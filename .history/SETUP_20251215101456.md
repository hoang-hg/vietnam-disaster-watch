# Hướng dẫn cài đặt & chạy — Viet Disaster Watch

Tài liệu ngắn gọn để thiết lập và chạy dự án trên Windows (không Docker) và bằng Docker.

**Yêu cầu cơ bản**
- Python 3.10+ (khuyến nghị 3.11)
- Node.js + npm
- Docker (tùy chọn)

**1) Chạy nhanh bằng Docker (khuyến nghị)**
```bash
cd viet-disaster-watch
# build và chạy frontend + backend
docker compose up --build
```
- Frontend: http://localhost:5173
- Backend: http://localhost:8000/docs

Trigger crawl thủ công trong container backend:
```bash
docker compose exec backend python -m app.crawler --once
```

**2) Chạy thủ công (Windows, không Docker)**

A) Backend
```powershell
cd backend
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
# (tuỳ chọn) set biến môi trường, ví dụ:
# $env:APP_DB_URL = "sqlite:///./data/app.db"
uvicorn app.main:app --reload --port 8000
```
- API docs: http://localhost:8000/docs
- Crawler tự khởi chạy theo `CRAWL_INTERVAL_MINUTES` thiết lập trong `docker-compose.yml` hoặc `settings`.
- Trigger thủ công:
```powershell
python -m app.crawler --once
```

B) Frontend
```powershell
cd frontend
npm install
npm run dev
```
- Mặc định dev server trên http://localhost:5173
- Nếu backend không chạy trên `http://localhost:8000`, chỉnh `VITE_API_BASE` hoặc dùng proxy.

**3) Biến môi trường & cấu hình quan trọng**
- `APP_DB_URL`: URL DB (mặc định sqlite `sqlite:///./data/app.db`).
- `CRAWL_INTERVAL_MINUTES`: khoảng thời gian scheduler (mặc định 10).
- `APP_TIMEZONE`: timezone cho scheduler (mặc định `Asia/Ho_Chi_Minh`).
- Danh sách nguồn/thiết lập crawl: chỉnh trong `backend/app/sources.py`.
- Các settings được load từ `backend/app/settings.py`.

**4) Dữ liệu & DB**
- DB SQLite mặc định lưu ở `backend/data/app.db` (volume trong docker-compose map tới `./backend/data`).

**5) Kiểm tra nhanh**
- Có một số file test (ví dụ `test_api_articles.py`, `backend/test_*.py`). Để chạy test, cài `pytest` và chạy:
```powershell
pip install pytest
pytest -q
```
(Giữ môi trường ảo đang active trong `backend`.)

**6) Lưu ý vận hành**
- Tôn trọng robots.txt khi scraping; hạn chế tần suất.
- Nếu deploy production, đổi SQLite sang PostgreSQL/MySQL và cấu hình `APP_DB_URL`.
- Nâng cấp NLP: `backend/app/nlp.py` có các hook để tích hợp mô hình lớn hơn.

---
Nếu bạn muốn, tôi có thể:
- Chạy thử backend local trên máy bạn (tôi sẽ đưa lệnh cụ thể),
- Tạo file `.env.example` với các biến môi trường, hoặc
- Commit `SETUP.md` vào repo cho bạn.
